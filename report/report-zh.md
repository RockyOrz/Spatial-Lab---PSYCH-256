# 最终报告（中文）：LLM 在 3D Mental Rotation 任务中的表现与置信度校准

## 摘要

本项目以经典心智旋转（mental rotation）范式为原型，评估多模态大语言模型（LLM）在三维视觉匹配任务中的能力：模型需要根据同一参考物体的两张视图（front 与 back/180°）在三个候选物体中选出“同一物体的 3D 旋转”，并报告置信度（confidence）。我们采用离线渲染（rendering）生成标准化刺激，并用 2×2×2 因子设计操控题目难度（对称性、旋转轴数量、旋转幅度），共 8 个条件、40 道题；随后用脚本在同一批题目上批量评估 4 个模型的准确率与置信度校准表现。

结果显示：4 个模型的总体准确率介于 30.0% 到 45.0%，95% Wilson 置信区间较宽（例如最高的 deepseek 为 45.0%，CI=[30.7%, 60.2%]），且与随机猜测（33.3%）相比未呈现稳健的显著优势（单侧二项检验最小 p=0.083）。同时，本题集正确答案分布不均（A=9、B=14、C=17），导致简单的“始终回答 C”基线即可达到 42.5%，使得部分模型的表面准确率需要结合基线与反应偏差一起解读。更重要的是，所有模型均表现出显著过度自信：平均置信度高达 79.2% 到 98.6%，但真实正确率仅 30% 到 45%；且置信度对对/错的区分度很弱（AUC 约 0.45 到 0.61），提示其元认知/校准能力有限。

**关键词**：心智旋转；空间想象；多模态大语言模型；置信度校准；元认知；基线比较

## 1. 引言

### 1.1 心智旋转与空间想象

心智旋转任务是经典的空间想象测量范式：被试需要在脑中对物体进行三维旋转，并判断两个视图是否属于同一物体。该能力在人类认知研究中常呈现稳定的“难度效应”，例如旋转幅度更大或旋转更复杂时更容易出错（也常伴随更长反应时）。因此，心智旋转可以作为评估“视觉-空间表征与变换能力”的一个清晰窗口。

### 1.2 研究动机：LLM 的视觉空间能力与元认知

近年的多模态模型已能处理图片输入，但它们是否具备接近人类的三维空间表征与心理旋转能力仍不明确。除了“能否答对”，本项目还关注“是否知道自己是否答对”：如果模型具有较好的元认知（metacognition），则在更难题或不确定时应降低置信度，呈现更好的置信度校准（confidence calibration）。

### 1.3 研究问题与假设

研究问题（RQ）：
1. 模型的识别准确率是否高于随机猜测（chance = 1/3）？不同模型间是否存在稳定差异？
2. 难度操控（对称性、旋转轴数量、旋转幅度）是否会系统性影响模型准确率？
3. 模型置信度是否与真实正确率匹配（校准良好），并随难度变化而调整？
4. 是否存在明显的选项偏好（A/B/C 输出分布不均），从而影响准确率解释？

假设（H）：
- H1（能力）：模型准确率略高于随机猜测，但明显低于人类（需在加入人类对照后检验）。
- H2（难度效应）：两轴旋转与大幅度旋转会降低准确率；低对称物体更难。
- H3（元认知）：模型存在过度自信（平均置信度显著高于正确率），且置信度对对/错的区分能力弱。
- H4（反应偏差）：部分模型存在强烈选项偏好，使“表面准确率”接近某些简单基线。

### 1.4 评估原则与本文结构

对 LLM 做“认知能力测试”时，一个常见误区是只展示少量例题与主观印象。为了更接近实验心理学的评估逻辑，我们参考了“以小步、系统化变体、明确基线和可复现记录”为核心的评估建议（Frank, 2023）：在同一任务框架下构造结构一致、条件可控的题目集；在比较模型准确率前先给出随机猜测与简单策略（如多数类）的基线；尽量减少上下文污染；并把 prompts 与输出完整保留在附录/仓库中。本文将依次介绍任务与刺激构造、模型测试与评分规则、定量指标、结果与讨论，并在最后给出后续改进方案。

## 2. 方法

### 2.1 刺激与题目结构

每道题包含 5 张图片：
- 两张参考视图：`1_Reference_Front.jpg` 与 `2_Reference_Back.jpg`
- 三张候选视图：`3_Target_A.jpg`、`3_Target_B.jpg`、`3_Target_C.jpg`

在仓库中，所有题目位于 `Trials/BatchRun_*/Trial_*`。每个 Trial 文件夹除图片外还包含一个 `Metadata.json`，记录该题所属条件与真值信息（哪一个候选为正确目标，以及候选的旋转参数）。其结构（节选）如下：

```json
{
  "config": { "shape": "HIGH_SYMMETRY", "complexity": "ONE_AXIS", "magnitude": "HIGH" },
  "targets": [
    { "id": "A", "is_correct": false, "rotation_values_deg": { "x": 0, "y": 0, "z": 137 } },
    { "id": "B", "is_correct": true,  "rotation_values_deg": { "x": 120, "y": 0, "z": 0 } },
    { "id": "C", "is_correct": false, "rotation_values_deg": { "x": 145, "y": 0, "z": 0 } }
  ]
}
```

我们以 `targets` 中 `is_correct=true` 的 `id` 作为该题正确答案，从而避免人工标注误差，并保证题目生成与评分的可复现性。

任务规则：
- 三个候选中仅 1 个与参考物体是同一物体（仅在 3D 中旋转）。
- 另外两个为结构性干扰项（structural distractors），即使旋转也无法与参考物体结构一致。
- 每题真值来自 `Metadata.json`（包含目标是否正确与旋转参数），便于量化评估与复现。

### 2.2 题目生成与标准化（渲染法 + 前端 demo）

我们采用离线渲染（rendering）批量生成刺激：使用同一套灯光与相机参数渲染物体在不同视角下的图像，保证题目在视觉呈现上的一致性，并可直接获得精确的真值旋转角度，便于后续统计分析。

为了更高效、可复现地生成与扩展题目集，我们使用 Google AI Studio，并借助刚发布不久的 Gemini 3 Pro（前端代码水平极强）快速搭建了一个前端 demo，用于批量生成基于“渲染法”的测试题。该工具显著提升了迭代效率，并帮助我们统一题目标准（命名、格式、元数据结构），从而更系统地构造不同难度条件的题目。

### 2.3 实验设计（2×2×2 因子设计）

我们操控三个二水平因素（来自 `report/project_proposal.md` 的设计）：
- **物体对称性**：HIGH_SYMMETRY vs LOW_SYMMETRY
- **旋转轴数量**：ONE_AXIS vs TWO_AXIS
- **旋转幅度**：LOW vs HIGH

因此共有 8 个条件（2×2×2）。当前题集每条件 5 题，总计 40 题（见 `Trials/BatchRun_*`）。

### 2.4 模型、提示词与运行设置

被试（模型）：
- `gpt5_2 (gpt-5.2)`
- `gemini (gemini-3-pro-preview)`
- `qwen (qwen-vl-plus)`
- `deepseek (deepseek-chat)`

程序要点：
- 每题在独立会话/独立调用中运行，尽量避免上下文窗口带来的污染。
- 统一提示词，要求模型输出 JSON 字段：`answer`（A/B/C）、`confidence`（0-100）、`reasoning`（简述）。
- 脚本默认采样温度 `temperature=0.2`（见 `scripts/run_llm_trials.py`）。

提示词说明：
- 完整 prompt 已保存在 `report/trials_result.md`。其核心结构是把模型设定为“mental rotation 测试的专家参与者”，强调“仅有一个候选为同一物体的 3D 旋转”，并强制输出 JSON 以便脚本解析与量化。摘录如下（节选）：

```text
System prompt: You are an expert participant in a Mental Rotation cognitive test.
Task:
- You see two views of a reference object (front + back/180° turn).
- You see three candidate objects labeled A, B, C.
- Exactly ONE candidate is the same object as the reference, merely rotated in 3D.
Output JSON fields:
- answer: "A" | "B" | "C"
- confidence: 0-100
- reasoning: brief why ...
User instruction: ... Reply ONLY with JSON: {"answer":"A|B|C","confidence":0-100,"reasoning":"..."}
```

### 2.5 批量测试与数据记录（run_llm_trials.py）

我们编写了 `scripts/run_llm_trials.py` 用于批量测试与量化：对同一批 40 道测试题批量调用 4 个模型，统一提示词与计分逻辑，逐题独立采样，收集答案与置信度，并将汇总结果自动追加写入 `report/trials_result.md`，以支持后续统计分析与可复现报告。
脚本开发过程中，我们也使用了 agent 工具（如 Codex CLI / gpt-codex 系列）辅助代码编写与调试。

### 2.6 评分规则与异常处理

为了保证“自动评分可复现”，我们将模型输出约束为 JSON，并在脚本中做了标准化处理：
- 若 `answer` 不是 A/B/C（或 JSON 解析失败），则该题记为无效输出，并在准确率统计中按“错误”计入。
- 若 `confidence` 缺失或无法解析，则该题在“置信度校准/区分度”分析中按缺失处理（不参与 ECE、Brier、AUC 等置信度相关指标）。

当前数据中，qwen 出现 1 题缺失输出（表格中为 `answer='-'`、`confidence='-'`）。这提示在扩大题量时应保留错误日志并进行必要的复跑或错误分析（例如区分超时、格式错误、空回复等）。

## 3. 指标与分析计划

### 3.1 表现指标（Performance）

- **总体准确率**：每模型 40 题正确比例。
- **不确定性表达**：由于样本量较小（每模型 n=40；每条件仅 n=5），报告总体准确率时同时给出 95% Wilson 置信区间；条件准确率仅作为探索性描述。
- **条件准确率**：每模型在 8 个条件下的正确率（每格 n=5；解释时强调不确定性）。
- **基线对照**：
  - 随机猜测基线：33.3%。
  - 多数类基线：始终回答本题集里最常见的正确选项（本题集为 C）。
- **反应偏差诊断**：报告 A/B/C 输出分布，并按“正确答案字母”分组报告正确率（例如 gold=A 时的正确率），用来识别“几乎不选某个字母”带来的结构性上限。

可选推断统计（题量足够时）：
- 二项检验（vs 1/3）或逻辑回归（Accuracy ~ Symmetry × Axis × Magnitude + Model）。在本文中，我们仅把二项检验作为探索性信息，并不把“显著/不显著”作为唯一结论依据。

### 3.2 置信度与校准（Metacognition / Calibration）

将 `confidence/100` 视为模型“主观正确概率”的粗略近似，计算：
- **Overconfidence gap**：mean(confidence) - accuracy（单位可用“百分点”表达）。
- **ECE（Expected Calibration Error）**：分箱后 |acc - conf| 的加权平均。
- **Brier score**：平均 (p - y)^2（越小越好）。
- **区分度**：mean_p(correct) - mean_p(wrong)（越大表示置信度越能区分对错）。
- **判别能力（discrimination）**：AUC（把 confidence 视为“对/错”的排序分数），以及 Pearson(confidence, correctness) 作为补充。

报告呈现建议（后续可补图）：
- 校准曲线/可靠性图（reliability diagram）
- Accuracy vs Avg Confidence 图

### 3.3 错误模式与偏差（Error pattern）

- **选项偏好**：统计 A/B/C 输出比例，与正确答案分布对照。
- **条件交互**：探索是否存在“某模型只在部分条件有效”的模式（当前每格 n=5，仅做探索性解读）。

## 4. 结果（基于 `report/trials_result.md`）

### 4.1 总体准确率、置信区间与基线

首先需要强调：本题集并不是“完美平衡”的三选一测试。40 题的正确答案分布为 A=9、B=14、C=17，因此“始终回答 C”的多数类基线可达 17/40=42.5%。这意味着：如果某个模型存在选项偏好（例如更倾向输出 C），它可能在不具备真实空间匹配能力的情况下获得看似不错的表面准确率。出于这个原因，我们同时报告随机猜测基线（33.3%）与多数类基线（42.5%），并在后续专门分析反应偏差。

表 1 汇总了 4 个模型在 40 题上的总体表现。可以看到：deepseek 的准确率最高（45.0%），但 95% Wilson 置信区间仍然较宽；单侧二项检验（vs 1/3）中，最小 p=0.083，尚不足以支持“稳健高于随机猜测”的结论。qwen 的准确率为 42.5%，与多数类基线完全相同，因此更需要结合其输出分布进一步解释。

| 模型 | 正确/总数 | 准确率 | 95% CI（Wilson） | p（单侧，vs 1/3） | 平均置信度 |
| --- | --- | --- | --- | --- | --- |
| gpt5_2 (gpt-5.2) | 15/40 | 37.5% | [24.2%, 53.0%] | 0.342 | 79.2 |
| gemini (gemini-3-pro-preview) | 12/40 | 30.0% | [18.1%, 45.4%] | 0.726 | 98.6 |
| qwen (qwen-vl-plus) | 17/40 | 42.5% | [28.5%, 57.8%] | 0.144 | 95.0 |
| deepseek (deepseek-chat) | 18/40 | 45.0% | [30.7%, 60.2%] | 0.083 | 92.0 |

### 4.2 条件准确率（每格 n=5）

| 条件 | gpt5_2 | gemini | qwen | deepseek |
| --- | --- | --- | --- | --- |
| HIGH_SYMMETRY \| ONE_AXIS \| HIGH | 40% | 60% | 100% | 60% |
| HIGH_SYMMETRY \| ONE_AXIS \| LOW | 20% | 40% | 80% | 20% |
| HIGH_SYMMETRY \| TWO_AXIS \| HIGH | 0% | 40% | 60% | 40% |
| HIGH_SYMMETRY \| TWO_AXIS \| LOW | 40% | 0% | 40% | 20% |
| LOW_SYMMETRY \| ONE_AXIS \| HIGH | 20% | 20% | 0% | 60% |
| LOW_SYMMETRY \| ONE_AXIS \| LOW | 40% | 60% | 40% | 40% |
| LOW_SYMMETRY \| TWO_AXIS \| HIGH | 80% | 20% | 20% | 60% |
| LOW_SYMMETRY \| TWO_AXIS \| LOW | 60% | 0% | 0% | 60% |

说明：由于每个条件只有 5 题，上表很容易受个别题目影响；当前更适合作为探索性结果，用于指导下一轮加题与平衡化。

### 4.3 因素汇总（探索性）

为了更直观地观察三个因素的潜在主效应，我们把 8 个条件按单一因素折叠汇总（每个水平 n=20）。需要再次强调：这仍然是探索性的，因为题量较小、且可能与具体题目/正确答案分布耦合。

对称性（HIGH_SYMMETRY vs LOW_SYMMETRY）：

| 模型 | HIGH_SYMMETRY | LOW_SYMMETRY |
| --- | --- | --- |
| gpt5_2 | 5/20 (25.0%) | 10/20 (50.0%) |
| gemini | 7/20 (35.0%) | 5/20 (25.0%) |
| qwen | 14/20 (70.0%) | 3/20 (15.0%) |
| deepseek | 7/20 (35.0%) | 11/20 (55.0%) |

旋转轴数量（ONE_AXIS vs TWO_AXIS）：

| 模型 | ONE_AXIS | TWO_AXIS |
| --- | --- | --- |
| gpt5_2 | 6/20 (30.0%) | 9/20 (45.0%) |
| gemini | 9/20 (45.0%) | 3/20 (15.0%) |
| qwen | 11/20 (55.0%) | 6/20 (30.0%) |
| deepseek | 9/20 (45.0%) | 9/20 (45.0%) |

旋转幅度（HIGH vs LOW）：

| 模型 | HIGH | LOW |
| --- | --- | --- |
| gpt5_2 | 7/20 (35.0%) | 8/20 (40.0%) |
| gemini | 7/20 (35.0%) | 5/20 (25.0%) |
| qwen | 9/20 (45.0%) | 8/20 (40.0%) |
| deepseek | 11/20 (55.0%) | 7/20 (35.0%) |

从这些折叠结果可以看到：不同模型的“难度效应”并不一致。例如，gemini 在 TWO_AXIS 条件下明显更差（15.0%），而 deepseek 在 HIGH 幅度下反而更好（55.0%）。这既可能反映模型策略差异，也可能是小样本噪声或题目分布偏差所致。因此我们在讨论中只把它们当作“下一轮实验需要重点检验的方向”，而不是稳定结论。

### 4.4 选项偏好（A/B/C 输出分布）

| 模型 | 输出A | 输出B | 输出C | 缺失/无效 |
| --- | --- | --- | --- | --- |
| gpt5_2 | 4 | 18 | 18 | 0 |
| gemini | 19 | 11 | 10 | 0 |
| qwen | 14 | 10 | 15 | 1 |
| deepseek | 2 | 24 | 14 | 0 |

该结果提示：不同模型存在明显的反应偏差（例如 deepseek 偏向回答 B，gemini 偏向回答 A），这会与“正确答案分布不均”共同影响准确率的解释。

进一步地，我们按“正确答案字母”分组查看正确率，以观察选项偏好带来的结构性影响（表 2）。其中最醒目的现象是：gpt5_2 与 deepseek 在 gold=A 的 9 道题上均为 0%，与它们“几乎不输出 A”的反应偏差一致。这说明：在三选一任务中，如果模型几乎不选择某个选项，那么即使它在其他题上表现尚可，总体能力也会被这种策略性偏差所限制。

| 模型 | gold=A（n=9） | gold=B（n=14） | gold=C（n=17） |
| --- | --- | --- | --- |
| gpt5_2 | 0/9 (0.0%) | 7/14 (50.0%) | 8/17 (47.1%) |
| gemini | 4/9 (44.4%) | 3/14 (21.4%) | 5/17 (29.4%) |
| qwen | 4/9 (44.4%) | 6/14 (42.9%) | 7/17 (41.2%) |
| deepseek | 0/9 (0.0%) | 9/14 (64.3%) | 9/17 (52.9%) |

### 4.5 置信度与校准

将置信度视为概率（p=confidence/100）后，可得到如下近似校准指标（缺失置信度的条目不计入校准计算；qwen 有 1 题缺失）：

| 模型 | 准确率 | 平均置信度 | 过度自信（百分点） | ECE10 | Brier | 区分度 Δp（正确-错误） |
| --- | --- | --- | --- | --- | --- | --- |
| gpt5_2 | 37.5% | 79.2% | +41.7 | 0.417 | 0.412 | -0.006 |
| gemini | 30.0% | 98.6% | +68.6 | 0.686 | 0.683 | -0.004 |
| qwen | 42.5% | 95.0% | +52.5 | 0.514 | 0.510 | +0.000 |
| deepseek | 45.0% | 92.0% | +47.0 | 0.470 | 0.461 | +0.019 |

简要结论：
- 所有模型都呈现显著过度自信（平均置信度远高于真实正确率）。
- 置信度对对/错的区分度很弱（Δp 接近 0），意味着“更自信”并不对应“更可能答对”，元认知/校准能力有限。

为了进一步检验“置信度是否能预测对/错”，我们补充报告置信度的离散程度与判别指标（表 3）。结果显示：qwen 的置信度在 39 个可用样本上完全恒定为 95（标准差 0），从信息论意义上几乎不可能区分对错；gpt5_2 与 gemini 的 AUC 甚至低于 0.5（接近反向预测）；deepseek 虽然 AUC 达到 0.607，但仍远称不上“校准良好”，更像是“略有区分度但强烈过度自信”。

| 模型 | 置信度样本数 | 置信度均值 | 置信度SD | 唯一值个数 | AUC | Pearson(conf,correct) |
| --- | --- | --- | --- | --- | --- | --- |
| gpt5_2 | 40 | 79.2 | 3.2 | 3 | 0.457 | -0.095 |
| gemini | 40 | 98.6 | 2.5 | 3 | 0.446 | -0.076 |
| qwen | 39 | 95.0 | 0.0 | 1 | 0.500 | NA |
| deepseek | 40 | 92.0 | 4.2 | 3 | 0.607 | 0.230 |

## 5. 讨论

### 5.1 主要发现（对应研究问题）

从总体表现看，我们并未观察到“稳健高于随机猜测”的证据：4 个模型的准确率为 30.0% 到 45.0%，置信区间较宽；即使表现最好的 deepseek，其单侧二项检验也仅达到 p=0.083。更关键的是，当把多数类基线（始终回答 C，42.5%）纳入比较后，deepseek 仅略高于该基线，而 qwen 与该基线相同。这说明：在当前题集与题量下，单看“总体准确率”很容易高估模型的空间能力。

其次，反应偏差在本任务中并非边缘现象，而是会直接塑造结论的核心因素。gpt5_2 与 deepseek 在 gold=A 的 9 道题上均为 0%，与它们几乎不输出 A 的分布一致；这表明模型可能采用了某种“偏好策略”或受解码/提示诱导影响，从而把三选一任务部分降维为“偏向某些选项的策略游戏”。如果不控制答案分布与偏好，后续任何关于“难度效应”的推断都会被混淆。

第三，关于难度操控（对称性、轴数量、幅度）的效应目前不稳定：折叠汇总后，不同模型呈现不同方向的变化（例如 gemini 在 TWO_AXIS 明显更差，而 deepseek 在 HIGH 幅度反而更好）。在每条件仅 5 题的情况下，我们更倾向把这些结果当作“下一轮需要更大样本验证的假设线索”，而不是对 H2 的确认或否定。

最后，置信度相关结果相当一致：所有模型都显著过度自信，且置信度对对/错的区分能力弱（AUC 约 0.45 到 0.61）。这支持了 H3，即便模型在某些题上能答对，它们也很难给出与真实不确定性相匹配的自我评估。

### 5.2 可能机制与解释

（1）从二维线索到三维表征的鸿沟：尽管任务以“3D 旋转匹配”表述，但模型未必真的形成三维结构表征。它们可能依赖局部纹理、轮廓或视角不变的二维线索做近似匹配；一旦遇到需要整合结构关系的干扰项，就容易失效。这类策略在小样本下可能偶尔奏效，但难以稳定泛化。

（2）提示词与对齐目标诱发的“高置信输出”：我们在 prompt 中把模型设定为“专家参与者”，并要求输出一个看似精确的 0-100 置信度数值。在对齐与生成习惯的共同作用下，模型可能倾向输出高置信、低离散的数值（例如 qwen 置信度恒定为 95），从而出现“语言上的确定性”与“任务上的不确定性”脱节。AUC 接近 0.5 也说明置信度更像是风格化输出，而不是可用的概率估计。

（3）反应偏差与题目分布耦合：三选一任务天然容易出现“偏选某个字母”的策略。一旦正确答案分布不均，这种偏好会被放大，甚至把总体准确率推到接近多数类基线。表 2 的结果说明，某些模型几乎不选 A，从而在 gold=A 的题目上系统性失败。未来实验必须平衡 A/B/C 的正确答案数量，并把“输出分布是否合理”作为质量控制的一部分。

### 5.3 局限性

- **题量偏小**：每条件仅 5 题，难以稳定估计条件效应与交互。
- **答案分布不均**：A/B/C 的正确答案频次不平衡，使多数类基线偏高，影响结论的可信度。
- **缺少人类对照数据**：当前报告仅包含模型结果，尚无法与人类心智旋转表现直接对比。
- **置信度测量粗糙**：置信度为单一标量，且不同模型对“置信度”的标定方式可能不一致；更合理的做法是输出选项概率分布并进行更严格的校准分析。
- **未分析 reasoning 的诊断价值**：当前主要做定量评估，尚未系统分析高置信错误的 reasoning 模式。

### 5.4 后续工作：把探索性结果变成可检验结论

基于以上局限与初步发现，我们计划按以下优先级推进下一轮实验，使报告从“探索性描述”升级为“可检验的经验结论”：

1. **增加题量并平衡答案分布**：每条件至少 20 题（总数建议 ≥160），并使正确答案在 A/B/C 中尽量均衡，避免多数类基线过高。
2. **加入人类对照组**：用同一刺激集测量人类被试（至少准确率；若可加入反应时，更贴近经典 mental rotation 研究的证据链）。
3. **重复性/一致性测试**：同一题对同一模型重复多次，评估“同题同答”的稳定性与随机性，从而区分“能力不足”与“输出噪声”。
4. **改进置信度测量**：要求输出 A/B/C 的概率分布（和为 1），再用 log loss、ECE、Brier 等指标评估校准，而不是依赖单一数值型 self-report。
5. **错误诊断与机制测试**：聚焦“高置信错误”样本，分析 reasoning 是否出现稳定的误判模式，并据此设计针对性的后续对照题。

## 6. 结论

在当前 40 题、8 条件的探索性数据上，多模态 LLM 在“基于两视图的 3D 旋转匹配”任务中尚未展现出稳健的超随机优势；同时，考虑到正确答案分布不均，多数类策略即可达到 42.5%，使得“总体准确率”不能直接等价为“空间推理能力”。我们观察到显著的选项偏好与结构性失败（例如某些模型在 gold=A 上系统性为 0%），这提示未来必须把反应偏差控制纳入实验设计本身。

与准确率相比，更一致的结论来自置信度：所有模型普遍过度自信，且置信度几乎不能有效区分对错，说明它们在该任务上的元认知/校准能力不足。下一步工作应优先扩大题量、平衡答案分布、加入人类对照，并采用更严格的概率输出与校准评估，从而更可靠地检验模型是否具备类人心智旋转能力以及其错误背后的机制。

## 参考文献（简要）

- Frank, M. C. (2023). Baby steps in evaluating the capacities of large language models. *Nature Reviews Psychology*, 2, 451-452.
- Shepard, R. N., & Metzler, J. (1971). Mental rotation of three-dimensional objects. *Science*, 171(3972), 701-703.

## 附录：提交材料清单与位置（课程要求）

- 题目刺激与真值：`Trials/`（每题文件夹包含 5 张图片与 `Metadata.json`）
- 统一提示词与模型输出汇总：`report/trials_result.md`（脚本自动追加；包含 prompt 与结果表）
- 批量运行与记录脚本：`scripts/run_llm_trials.py`

提交注意：
- 课程要求报告附录中完整包含“所有 prompts 与对应输出”。本仓库中 `report/trials_result.md` 已包含统一 prompt 与每题结果的汇总表；若提交为 PDF，建议将该文件内容（或脚本运行日志/原始 JSON 输出）整理为附录随报告一并提交。
- 报告组织与评分标准对应关系：引言部分提供概念解释与理论背景；方法部分详细说明测试与执行；结果部分呈现核心数据与图表；讨论/结论部分解释结果、说明局限并提出未来改进；全文强调清晰表达与可复现性。
